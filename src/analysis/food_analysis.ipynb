{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.subplots as sp\n",
    "import unicodedata\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "from typing import Dict, List, Union, Tuple\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conectar o banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\Desktop\\Portifolio\\curriculo-online\\.venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1933: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-05-11 08:28:07,152 - root - INFO - Successfully loaded 1000 rows from BigQuery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 1000 rows\n",
      "\n",
      "First 5 rows:\n",
      "              id           code            product_name  \\\n",
      "0  6111035000430  6111035000430                Sidi Ali   \n",
      "1  6111242100992  6111242100992                   Perly   \n",
      "2  6111035002175  6111035002175                Sidi Ali   \n",
      "3  6111035000058  6111035000058  Eau minérale naturelle   \n",
      "4  6111252421568  6111252421568                اكوافينا   \n",
      "\n",
      "                                 brands  \\\n",
      "0                              Sidi Ali   \n",
      "1                                Jaouda   \n",
      "2                              sidi ali   \n",
      "3  Les Eaux Minérales d'oulmès,Sidi Ali   \n",
      "4                         pepsi,PepsiCo   \n",
      "\n",
      "                                          categories  \\\n",
      "0  Beverages and beverages preparations,Beverages...   \n",
      "1  Dairies,Fermented foods,Fermented milk product...   \n",
      "2  beverages-and-beverages-preparations, beverage...   \n",
      "3  Beverages and beverages preparations,Beverages...   \n",
      "4  Boissons et préparations de boissons,Boissons,...   \n",
      "\n",
      "                                    ingredients_text  \\\n",
      "0                         une eau minérale naturelle   \n",
      "1  Lait écrémé, crème, SUcre, ferments laciques M...   \n",
      "2  Sodium 26 Calcium 12 Magnésium 9 Potassium 3 B...   \n",
      "3                                  100% EAU MINÉRALE   \n",
      "4  ouverture et avant le : Voir bouteille. après ...   \n",
      "\n",
      "                                          nutriments  \\\n",
      "0  {\"carbohydrates\": 42, \"carbohydrates_100g\": 4....   \n",
      "1  {\"calcium\": 0.25, \"calcium_100g\": 0.25, \"calci...   \n",
      "2  {\"chloride\": 0.014, \"chloride_serving\": 0.014,...   \n",
      "3  {\"fruits-vegetables-legumes-estimate-from-ingr...   \n",
      "4  {\"alcohol\": 0, \"alcohol_100g\": 0, \"alcohol_ser...   \n",
      "\n",
      "                  created_datetime           last_modified_datetime quantity  \\\n",
      "0 2025-05-10 10:02:46.761206+00:00 2025-05-10 10:02:46.761206+00:00    33 cl   \n",
      "1 2025-05-10 10:02:46.762203+00:00 2025-05-10 10:02:46.762203+00:00     80.0   \n",
      "2 2025-05-10 10:02:46.762203+00:00 2025-05-10 10:02:46.762203+00:00      2 L   \n",
      "3 2025-05-10 10:02:46.762203+00:00 2025-05-10 10:02:46.762203+00:00    1,5 L   \n",
      "4 2025-05-10 10:02:46.762203+00:00 2025-05-10 10:02:46.762203+00:00     33cl   \n",
      "\n",
      "  serving_size  energy_100g  proteins_100g  carbohydrates_100g  fat_100g  \\\n",
      "0           1l          0.0            0.0                 4.2       0.0   \n",
      "1         None         97.0            8.0                 9.4       3.0   \n",
      "2         None          NaN            NaN                 NaN       NaN   \n",
      "3         None          NaN            NaN                 NaN       NaN   \n",
      "4           1l          0.0            0.0                 0.0       0.0   \n",
      "\n",
      "   fiber_100g  sodium_100g  sugars_100g  \n",
      "0         0.0     0.000000          1.4  \n",
      "1         NaN          NaN          NaN  \n",
      "2         NaN          NaN          NaN  \n",
      "3         NaN          NaN          NaN  \n",
      "4         0.0     0.000203          0.0  \n"
     ]
    }
   ],
   "source": [
    "%run \"C:\\Users\\lopes\\Desktop\\Portifolio\\curriculo-online\\src\\analysis\\db_connection.py\"\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent.parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopes\\Desktop\\Portifolio\\curriculo-online\\.venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1933: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n",
      "2025-05-11 08:28:10,825 - root - INFO - Successfully loaded 1000 rows from BigQuery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Analise de dados inicial ===\n",
      "\n",
      "Primeiras 5 linhas:\n",
      "              id           code            product_name  \\\n",
      "0  6111035000430  6111035000430                Sidi Ali   \n",
      "1  6111242100992  6111242100992                   Perly   \n",
      "2  6111035002175  6111035002175                Sidi Ali   \n",
      "3  6111035000058  6111035000058  Eau minérale naturelle   \n",
      "4  6111252421568  6111252421568                اكوافينا   \n",
      "\n",
      "                                 brands  \\\n",
      "0                              Sidi Ali   \n",
      "1                                Jaouda   \n",
      "2                              sidi ali   \n",
      "3  Les Eaux Minérales d'oulmès,Sidi Ali   \n",
      "4                         pepsi,PepsiCo   \n",
      "\n",
      "                                          categories  \\\n",
      "0  Beverages and beverages preparations,Beverages...   \n",
      "1  Dairies,Fermented foods,Fermented milk product...   \n",
      "2  beverages-and-beverages-preparations, beverage...   \n",
      "3  Beverages and beverages preparations,Beverages...   \n",
      "4  Boissons et préparations de boissons,Boissons,...   \n",
      "\n",
      "                                    ingredients_text  \\\n",
      "0                         une eau minérale naturelle   \n",
      "1  Lait écrémé, crème, SUcre, ferments laciques M...   \n",
      "2  Sodium 26 Calcium 12 Magnésium 9 Potassium 3 B...   \n",
      "3                                  100% EAU MINÉRALE   \n",
      "4  ouverture et avant le : Voir bouteille. après ...   \n",
      "\n",
      "                                          nutriments  \\\n",
      "0  {\"carbohydrates\": 42, \"carbohydrates_100g\": 4....   \n",
      "1  {\"calcium\": 0.25, \"calcium_100g\": 0.25, \"calci...   \n",
      "2  {\"chloride\": 0.014, \"chloride_serving\": 0.014,...   \n",
      "3  {\"fruits-vegetables-legumes-estimate-from-ingr...   \n",
      "4  {\"alcohol\": 0, \"alcohol_100g\": 0, \"alcohol_ser...   \n",
      "\n",
      "                  created_datetime           last_modified_datetime quantity  \\\n",
      "0 2025-05-10 10:02:46.761206+00:00 2025-05-10 10:02:46.761206+00:00    33 cl   \n",
      "1 2025-05-10 10:02:46.762203+00:00 2025-05-10 10:02:46.762203+00:00     80.0   \n",
      "2 2025-05-10 10:02:46.762203+00:00 2025-05-10 10:02:46.762203+00:00      2 L   \n",
      "3 2025-05-10 10:02:46.762203+00:00 2025-05-10 10:02:46.762203+00:00    1,5 L   \n",
      "4 2025-05-10 10:02:46.762203+00:00 2025-05-10 10:02:46.762203+00:00     33cl   \n",
      "\n",
      "  serving_size  energy_100g  proteins_100g  carbohydrates_100g  fat_100g  \\\n",
      "0           1l          0.0            0.0                 4.2       0.0   \n",
      "1         None         97.0            8.0                 9.4       3.0   \n",
      "2         None          NaN            NaN                 NaN       NaN   \n",
      "3         None          NaN            NaN                 NaN       NaN   \n",
      "4           1l          0.0            0.0                 0.0       0.0   \n",
      "\n",
      "   fiber_100g  sodium_100g  sugars_100g  \n",
      "0         0.0     0.000000          1.4  \n",
      "1         NaN          NaN          NaN  \n",
      "2         NaN          NaN          NaN  \n",
      "3         NaN          NaN          NaN  \n",
      "4         0.0     0.000203          0.0  \n",
      "\n",
      "Últimas 5 linhas:\n",
      "                id           code                   product_name  \\\n",
      "995  8424893600321  8424893600321                          Kéfir   \n",
      "996  6111246722107  6111246722107                 Frommage fondu   \n",
      "997  3175681028098  3175681028098  Galettes boulghour & épeautre   \n",
      "998  3182180060320  3182180060320   Tartines de Pain Blé Complet   \n",
      "999  7614500010013  7614500010013                      Toblerone   \n",
      "\n",
      "                  brands                                         categories  \\\n",
      "995                Reina                                      Kefir yogurts   \n",
      "996      REWE Beste Wahl  Dairies, Fermented foods, Fermented milk produ...   \n",
      "997           Céréal Bio  Alternatives à la viande, Galettes végétarienn...   \n",
      "998     Brioche Pasquier  Aliments et boissons à base de végétaux,Alimen...   \n",
      "999  Mondeléz, Toblerone  Botanas,Snacks dulces,Cacao y sus productos,Du...   \n",
      "\n",
      "                                      ingredients_text  \\\n",
      "995  تحلية الكفير 500غ مكونات: حليب نصف منزوع الدسم...   \n",
      "996  Lait de Vache pasteurisé, Crème fraiche pasteu...   \n",
      "997  Boulghour de blé complet* réhydraté 44,3 %, ép...   \n",
      "998  Farine de BLÉ, Farine de BLÉ complet 17% , Son...   \n",
      "999  sugar, whole milk powder, cocoa butter, cocoa ...   \n",
      "\n",
      "                                            nutriments  \\\n",
      "995  {\"carbohydrates\": 5.5, \"carbohydrates_100g\": 5...   \n",
      "996  {\"carbohydrates\": 9, \"carbohydrates_100g\": 9, ...   \n",
      "997  {\"carbohydrates\": 25, \"carbohydrates_100g\": 25...   \n",
      "998  {\"carbohydrates\": 67, \"carbohydrates_100g\": 67...   \n",
      "999  {\"carbohydrates\": 61, \"carbohydrates_100g\": 61...   \n",
      "\n",
      "                    created_datetime           last_modified_datetime  \\\n",
      "995 2025-05-10 10:03:32.789913+00:00 2025-05-10 10:03:32.789913+00:00   \n",
      "996 2025-05-10 10:03:32.789913+00:00 2025-05-10 10:03:32.789913+00:00   \n",
      "997 2025-05-10 10:03:32.789913+00:00 2025-05-10 10:03:32.789913+00:00   \n",
      "998 2025-05-10 10:03:32.789913+00:00 2025-05-10 10:03:32.789913+00:00   \n",
      "999 2025-05-10 10:03:32.789913+00:00 2025-05-10 10:03:32.789913+00:00   \n",
      "\n",
      "              quantity                                   serving_size  \\\n",
      "995               500g                                         500.0g   \n",
      "996                1kg                                           None   \n",
      "997  200 g (2 x 100 g)                                           100g   \n",
      "998      240 g (24 tr)                                    20 g (2 tr)   \n",
      "999              100 g  3 triangle/kolmiota/dreiecke/trianglar (25 g)   \n",
      "\n",
      "     energy_100g  proteins_100g  carbohydrates_100g  fat_100g  fiber_100g  \\\n",
      "995         75.0            3.9                 5.5       4.2         NaN   \n",
      "996        298.0            7.0                 9.0      26.0         0.0   \n",
      "997        186.0            5.0                25.0       5.2         6.2   \n",
      "998        382.0           13.0                67.0       5.0         8.7   \n",
      "999        528.0            5.6                61.0      28.0         2.4   \n",
      "\n",
      "     sodium_100g  sugars_100g  \n",
      "995     0.059055          5.5  \n",
      "996     0.480000          4.0  \n",
      "997     0.380000          3.8  \n",
      "998     0.600000          4.2  \n",
      "999     0.048000         60.0  \n"
     ]
    }
   ],
   "source": [
    "from src.analysis.db_connection import load_data\n",
    "\n",
    "# Load data\n",
    "df = load_data()\n",
    "\n",
    "# Basic inspection\n",
    "print(\"\\n=== Analise de dados inicial ===\")\n",
    "print(\"\\nPrimeiras 5 linhas:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nÚltimas 5 linhas:\")\n",
    "print(df.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza  dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remover os dados Nulos da  colunas de nomes, categorias e marcas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento de dados\n",
    "\n",
    "df =  df.dropna()\n",
    "\n",
    "def text_clean(text):\n",
    "    text = str(text).strip()\n",
    "    text = \" \".join(text.split())\n",
    "    text = ''.join(\n",
    "        c for c in unicodedata.normalize('NFKD', text)\n",
    "        if not unicodedata.combining(c)\n",
    "    )\n",
    "    text = text.upper()\n",
    "    return text\n",
    "\n",
    "df['product_name'] = df['product_name'].apply(text_clean)\n",
    "df['categories'] = df['categories'].apply(text_clean)\n",
    "df['brands'] = df['brands'].apply(text_clean)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para limpar e padronizar os textos das marcas\n",
    "\n",
    "    Limpas e padronizar o texto da coluna 'brand':\n",
    "    1. Removendo espaços extras \n",
    "    2. Normalizar caracteres usando UNICODE\n",
    "    3. Converter tudo para maisculo\n",
    "    4. Remover caracteres especiais\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input de texto para limpas\n",
    "        \n",
    "    Returns:\n",
    "        str: Texto limpo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_brand_text(text: str) -> str:\n",
    "\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Converte para uma string e remove os caracteres especiais\n",
    "    text = str(text).strip('[]').strip('\"').strip(\"'\").strip()\n",
    "    \n",
    "    # Normaliza os caracteres usando UNICODE (NFKD decomposition)\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    \n",
    "    # Remove os acentos\n",
    "    text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "    \n",
    "    # Converte para maisculo\n",
    "    text = text.upper()\n",
    "    \n",
    "    # Remove caracteres especiais mas mantendo espaços e pontuação\n",
    "    text = re.sub(r'[^\\w\\s\\-&]', '', text)\n",
    "    \n",
    "    # Remove espaços extras\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para padronizar a coluna brand    \n",
    "    Padronizara listas de marcas que tiver em uma unica string\n",
    "    \n",
    "    Args:\n",
    "        brands (Union[str, List[str]]): Input marcas como string ou lista\n",
    "        \n",
    "    Returns:\n",
    "        str: Padronizar a string da marca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_brand_list(brands: Union[str, List[str]]) -> str:\n",
    "\n",
    "    if isinstance(brands, str):\n",
    "        brands = [brand.strip() for brand in brands.split(',')]\n",
    "    return ', '.join(clean_brand_text(brand) for brand in brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa os dados do dicionario criado em um arquivo json:\n",
    "\n",
    "    Mapeamento de marcas para padronização\n",
    "    \n",
    "    Args:\n",
    "        mapping (dict): Dicionário de mapeamento de marcas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brand_mapping() -> Dict[str, str]:\n",
    "\n",
    "    mapping_file = Path(r\"C:\\Users\\lopes\\Desktop\\Portifolio\\curriculo-online\\src\\analysis\\brand_mapping.json\")\n",
    "    if mapping_file.exists():\n",
    "        with open(mapping_file, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procurar marcas similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_brands(brand: str, existing_brands: List[str], threshold: float = 80.0) -> List[Tuple[str, float]]:\n",
    "\n",
    "    similar_brands = []\n",
    "    for existing_brand in existing_brands:\n",
    "        score = fuzz.ratio(brand, existing_brand)\n",
    "        if score >= threshold:\n",
    "            similar_brands.append((existing_brand, score))\n",
    "    return sorted(similar_brands, key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar um double check nas marcas para verificar as não mapeadas e achar possiveis marcas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_unmapped_brands(df: pd.DataFrame, mapping: Dict[str, str]) -> pd.DataFrame:\n",
    "\n",
    "    # Get unique brands from the dataset\n",
    "    all_brands = df['brands'].unique()\n",
    "    \n",
    "    # Find unmapped brands\n",
    "    unmapped_brands = [brand for brand in all_brands if brand not in mapping]\n",
    "    \n",
    "    # Get list of mapped brands (values in the mapping dictionary)\n",
    "    mapped_brands = list(set(mapping.values()))\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results = []\n",
    "    for brand in unmapped_brands:\n",
    "        similar = find_similar_brands(brand, mapped_brands)\n",
    "        if similar:\n",
    "            results.append({\n",
    "                'unmapped_brand': brand,\n",
    "                'potential_matches': similar,\n",
    "                'suggested_mapping': similar[0][0] if similar[0][1] >= 90 else None\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atualizar o dicionario do arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_brand_mapping(df: pd.DataFrame, auto_accept_threshold: float = 90.0) -> pd.DataFrame:\n",
    "  \n",
    "    # Load existing mapping\n",
    "    mapping = get_brand_mapping()\n",
    "    \n",
    "    # Analyze unmapped brands\n",
    "    unmapped_analysis = analyze_unmapped_brands(df, mapping)\n",
    "    \n",
    "    # Auto-accept high-confidence mappings\n",
    "    high_confidence = unmapped_analysis[\n",
    "        unmapped_analysis['potential_matches'].apply(\n",
    "            lambda x: x[0][1] >= auto_accept_threshold if x else False\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Create new mappings dictionary\n",
    "    new_mappings = {\n",
    "        row['unmapped_brand']: row['suggested_mapping']\n",
    "        for _, row in high_confidence.iterrows()\n",
    "    }\n",
    "    \n",
    "    # Save updated mapping\n",
    "    if new_mappings:\n",
    "        save_brand_mapping(new_mappings)\n",
    "    \n",
    "    # Return unmapped brands that need manual review\n",
    "    return unmapped_analysis[\n",
    "        unmapped_analysis['potential_matches'].apply(\n",
    "            lambda x: x[0][1] < auto_accept_threshold if x else True\n",
    "        )\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvar o arquivo json do dicionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_brand_mapping(mapping: Dict[str, str]) -> None:\n",
    "\n",
    "    mapping_file = Path('data/brand_mapping.json')\n",
    "    mapping_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Load existing mappings if file exists\n",
    "    existing_mapping = {}\n",
    "    if mapping_file.exists():\n",
    "        with open(mapping_file, 'r', encoding='utf-8') as f:\n",
    "            existing_mapping = json.load(f)\n",
    "    \n",
    "    # Update with new mappings\n",
    "    existing_mapping.update(mapping)\n",
    "    \n",
    "    # Save updated mappings\n",
    "    with open(mapping_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(existing_mapping, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processar e padronizar a coluna brand no dataframe:\n",
    "\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe com a coluna 'brands'\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe com a coluna 'brands' padronizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_brands(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    # Load mapping\n",
    "    mapping = get_brand_mapping()\n",
    "    \n",
    "    # Clean and standardize brands\n",
    "    df['brands_clean'] = df['brands'].apply(clean_brand_text)\n",
    "    \n",
    "    # Apply mapping\n",
    "    df['brands_final'] = df['brands_clean'].map(mapping).fillna(df['brands_clean'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para os dados não foram mapeados pelos os nomes padrão do primeiro dicionarios:\n",
    "\n",
    "    Get list of brands that weren't mapped to any standard name.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Processed dataframe with 'brands' column\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: List of unmapped brand names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unmapped_brands(df: pd.DataFrame) -> List[str]:\n",
    "\n",
    "    mapping = get_brand_mapping()\n",
    "    return sorted(df.loc[~df['brands'].isin(mapping.values()), 'brands'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id           code                   product_name  \\\n",
      "0   6111035000430  6111035000430                       SIDI ALI   \n",
      "4   6111252421568  6111252421568                       اكوافينا   \n",
      "6   3274080005003  3274080005003  CRISTALINE EAU DE SOURCE 1.5L   \n",
      "23  6111242106949  6111242106949                           JBEN   \n",
      "24  6111128000071  6111128000071                      AIN SAISS   \n",
      "\n",
      "              brands                                         categories  \\\n",
      "0         [SIDI ALI]  BEVERAGES AND BEVERAGES PREPARATIONS,BEVERAGES...   \n",
      "4   [PEPSI, PEPSICO]  BOISSONS ET PREPARATIONS DE BOISSONS,BOISSONS,...   \n",
      "6       [CRISTALINE]  BOISSONS ET PREPARATIONS DE BOISSONS,BOISSONS,...   \n",
      "23          [JAOUDA]  EN:DAIRIES, EN:FERMENTED FOODS, EN:FERMENTED M...   \n",
      "24          [DANONE]  BOISSONS,EAUX,EAUX DE SOURCES,EAUX MINERALES,B...   \n",
      "\n",
      "                                     ingredients_text  \\\n",
      "0                          une eau minérale naturelle   \n",
      "4   ouverture et avant le : Voir bouteille. après ...   \n",
      "6                                       Eau de source   \n",
      "23  lait frais entier, crème, stabilisants, amidon...   \n",
      "24                             Eau minérale naturelle   \n",
      "\n",
      "                                           nutriments  \\\n",
      "0   {\"carbohydrates\": 42, \"carbohydrates_100g\": 4....   \n",
      "4   {\"alcohol\": 0, \"alcohol_100g\": 0, \"alcohol_ser...   \n",
      "6   {\"alpha-linolenic-acid\": 0.219, \"alpha-linolen...   \n",
      "23  {\"alcohol\": 0, \"alcohol_100g\": 0, \"alcohol_ser...   \n",
      "24  {\"alcohol\": 0, \"alcohol_100g\": 0, \"alcohol_ser...   \n",
      "\n",
      "                   created_datetime           last_modified_datetime quantity  \\\n",
      "0  2025-05-10 10:02:46.761206+00:00 2025-05-10 10:02:46.761206+00:00    33 cl   \n",
      "4  2025-05-10 10:02:46.762203+00:00 2025-05-10 10:02:46.762203+00:00     33cl   \n",
      "6  2025-05-10 10:02:46.762203+00:00 2025-05-10 10:02:46.762203+00:00  1500 ml   \n",
      "23 2025-05-10 10:02:46.763200+00:00 2025-05-10 10:02:46.763200+00:00     160g   \n",
      "24 2025-05-10 10:02:46.763200+00:00 2025-05-10 10:02:46.763200+00:00    1.5 l   \n",
      "\n",
      "   serving_size  energy_100g  proteins_100g  carbohydrates_100g  fat_100g  \\\n",
      "0            1l          0.0            0.0                 4.2       0.0   \n",
      "4            1l          0.0            0.0                 0.0       0.0   \n",
      "6            1l          0.0            0.0                 0.0       0.0   \n",
      "23         160g        235.0            8.0                 3.5      21.0   \n",
      "24           1l          0.0            0.0                 0.0       0.0   \n",
      "\n",
      "    fiber_100g  sodium_100g  sugars_100g  \n",
      "0          0.0     0.000000          1.4  \n",
      "4          0.0     0.000203          0.0  \n",
      "6          0.0     0.021000          0.0  \n",
      "23         0.0     0.184000          0.0  \n",
      "24         0.0     0.000000          0.0  \n"
     ]
    }
   ],
   "source": [
    "def analyze_brand_distribution(df: pd.DataFrame) -> pd.Series:\n",
    "\n",
    "    return df['brands'].value_counts() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
